** Workflow changes

*** Model extension to MIMIC-III with conditional framework
***** TODO current architecture can easily be extrapolated to in-hospital-mortality data generation task
***** TODO visualize data from MIMIC-III github repository in 2-dimensions to see smoothness or roughness
***** TODO use same color frame range for even comparison
***** TODO work on extension to MIMIC-III data with evaluation protocols
***** TODO start working on mortality data generation with descriptive statistics first
***** consider using encoder-decoder or transformers in GAN for variable sequence length generation
***** consider changing RGAN name to CRGAN (convolutional-recurrent-GAN), with conditional one as CRAGAN (auxiliary as addition)
***** use ETH model on MIMIC-III and compare evaluations with own model
***** apply RCGAN technique towards this process and verify results with existing models through TSTR/TRTS and MMD checks
***** add custom image shapes and prepare code to shift away from square images
***** read on more innovative semi-supervised gan architectures that we could also use
***** replace discriminator with existing supervised network to see how that can work better
***** before publication, publish some of the preliminary models used

*** Model visualization and presentation
***** TODO enforce tensorflow-gpu=1.14.0 in requirements.txt, or have it based on morty
***** fix column enforcements and add documentation for log files
***** add extra option to ignore pics/gifs when cloning unless prompted
***** add function to generate best samples from trained model aside from already generated images
***** change matplotlib backend default back to instant working version when necessary

*** Model stabilization and abstraction
***** TODO port code to tf 1.15 for security or tensorflow2/pytorch for better integration -> might solve problem with accuracy printing based on non-binary target labels
***** work on introspection tasks, where data is passed through layers step-wise and results are manually/automatically checked for explainability
***** consider borrowing model architecture from other successful models and employ within local biomedical task
***** consider that performance on images is not paramount, abstraction to medical data and construction of local evaluation techniques is more important
***** consider developing online per-epoch similarity checks, MMD and TRTS to check quality of samples
***** look up ganhacks for further possible improvements such as adding leaky-relu everywhere, and read on successful/innovative gan architectures
***** make pipeline variable/adaptable/scalable to higher (possibly non-square) dimensional data in case of 64 dimensional lfw faces (user more variables in models instead of hard-coding)
***** read papers for strategies/uses of synthetic data

*** Heuristics
***** add convergent pathway polynomial fit to check whether training is diverging or converging in given time frame
***** add gradient checks for logging and change vis.py to include colour on loss line for gradients
***** use tensorboard to analyze learning process
***** develop similarity/quality metrics which could be used alongside training

*** Possible architecture improvements
***** use Wasserstein loss with standard or improved training
***** try out vae architecture within generation process
***** think more about constraining gradients in various network parts to achieve some interpretability
***** think more about complex networks integration
***** use feature matching and minibatch discrimination to prevent mode collapse
***** consider adding Gaussian noise to images for stability (mixed outcomes predicted)
***** consider resnet architecture for certain skip-connections, could be linked to multi-scale gradient structure

*** Miscellaneous
***** models appear more stable when discriminator is significantly less powerful than generator
***** models are more stable when same noisy labels are used for discriminator
***** track how many epochs or batch runs needed to converge and try to optimize this (~500/2000 for mnist/lfw respectively)
***** add MIMIC-III 2d projection depiction and learning as gif on initial readme
***** remove caveats in readme once relevant developments are complete

*** High-level ideas
**** GAN stabilisation:
***** Gaussian label smoothing
***** differing learning rates for optimizers
***** Gaussian noise addition to images
***** spectral normalization
***** multi-scale gradient
**** Evaluation pipeline
***** use MIMIC data/models for direct MMD + TSTR/TRTS validations
***** explore privacy perspective and whether GAN is able to remove personal traits
***** or consider another architecture which can perform this function
**** Networks and higher-dimensions abstraction
***** extend to deeper model which can handle 64 pixels faces to check if abstraction possible
***** extend to RCGAN with realistic conditionings for actual usable data genration
**** Input images and feature masking
***** come up with mask to simulate missing data in real-life
***** compare input and output images as time series with signals
**** Documentation and code-health:
***** fix unused imports and sort with python tools
***** make detailed documentation and model visualizations
      
